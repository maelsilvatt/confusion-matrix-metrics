# Confusion Matrix and Derived Metrics Example
This repository contains an example of how to generate and interpret a confusion matrix for a binary classification problem. Additionally, the repository provides an example of how to compute precision, recall, F1-score, and accuracy using the confusion matrix.

## Usage
The repository contains a Jupyter notebook `confusion_matrix_example.ipynb which demonstrates how to generate a confusion matrix and calculate precision, recall, F1-score, and accuracy. The notebook also includes a brief explanation of each of these metrics.

## References
- [Wikipedia - Confusion Matrix](https://en.wikipedia.org/wiki/Confusion_matrix)
- [Scikit-learn - Confusion Matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)
- [Scikit-learn - Classification Metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)